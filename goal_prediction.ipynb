{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.config' from '/home/deus/Documents/trajectory-prediction/src/config.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from src import parsing\n",
    "from src import model_path\n",
    "from src import models_path\n",
    "from src import model_goal\n",
    "from src import models_goal\n",
    "from src import model_interface\n",
    "from src import visualization\n",
    "from src import util\n",
    "from src import config\n",
    "reload(parsing)\n",
    "reload(model_path)\n",
    "reload(models_path)\n",
    "reload(model_goal)\n",
    "reload(models_goal)\n",
    "reload(model_interface)\n",
    "reload(visualization)\n",
    "reload(util)\n",
    "reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1058/1058 [00:16<00:00, 63.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing 580 human trajectories: 11 training, 569 eval, 0 test\n",
      "train (6670, 40, 2) float64 (6670, 25) float32 (6670, 40, 2) float64\n",
      "eval (240985, 40, 2) float64 (240985, 25) float32 (240985, 40, 2) float64\n"
     ]
    }
   ],
   "source": [
    "# load input\n",
    "# since we use a different file then for training we can use everything for eval\n",
    "file_path = \"data/medium_ab.csv\"\n",
    "_, eval_data, _ = parsing.parse_atc_day(file_path, train_ratio=0.02, eval_ratio=0.98)\n",
    "input_path, correct_goals, ground_truth_path = eval_data\n",
    "\n",
    "# limit amount of data used to avoid memory overflow\n",
    "LIMIT = 5000\n",
    "input_path = input_path[:LIMIT,:,:]\n",
    "correct_goals = correct_goals[:LIMIT,:]\n",
    "ground_truth_path = ground_truth_path[:LIMIT,:,:]\n",
    "eval_data = input_path, correct_goals, ground_truth_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate estimates\n",
    "m = model_goal.ModelGoal()\n",
    "m.load('goal_simple_cnn')\n",
    "goals_estimation = m.estimate(eval_data)\n",
    "\n",
    "# free memory\n",
    "m = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(model_path)\n",
    "\n",
    "# load predictive model\n",
    "m = model_path.ModelPath(uses_goal=True)\n",
    "m.load('path_simple_lstm_goal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MED: 0.030914461425584034\n",
      "FDE: 0.04430704503859379\n"
     ]
    }
   ],
   "source": [
    "# evaluate gt goals\n",
    "m.metrics(input_path, ground_truth=ground_truth_path, goals=correct_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MED: 0.035027690295997796\n",
      "FDE: 0.05504289714568437\n"
     ]
    }
   ],
   "source": [
    "# evaluate estimated goals\n",
    "m.metrics(input_path, ground_truth=ground_truth_path, goals=goals_estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length ADE distances 200000, ground truth shape (5000, 40, 2)\n",
      "Length FDE distances 5000, ground truth shape (5000, 40, 2)\n",
      "ADE: 0.04046657588548339\n"
     ]
    }
   ],
   "source": [
    "reload(model_path)\n",
    "reload(util)\n",
    "m = None\n",
    "m = model_path.ModelPath(uses_goal=False)\n",
    "m.load('path_simple_lstm')\n",
    "\n",
    "# evaluate without goals\n",
    "m.metrics_geometric(input_path, ground_truth=ground_truth_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
